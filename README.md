# LLM-Reasoning-Error-Taxonomy

Understanding How Large Language Models Fail at Reasoning
A structured analysis of reasoning failure modes across LLMs, focusing on interpretability, reliability, and human-aligned evaluation.
